{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch13.JHpart.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+RWRiG55M+n2xcuLaa7Tm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmk9/Deeplearning_seminar/blob/master/ch13_JHpart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C_7B5kPn4Kg",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1: Introduction to Tensors**\n",
        "\n",
        "\n",
        "\n",
        "> Tensor class가 모든 수치 정보를 Numpy 배열(self.data)에 담고, 한 가지 텐서 연산을 지원\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHu6rhBqn2fl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6f250f85-b5f2-4ca1-e16d-11280d80806f"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class Tensor (object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = np.array(data)\n",
        "    \n",
        "    def __add__(self, other):\n",
        "        return Tensor(self.data + other.data)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())\n",
        "    \n",
        "x = Tensor([1,2,3,4,5])\n",
        "print(x)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3 4 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBkRLVgsn3wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c1a6c8ee-b2ae-453b-91ad-c3b221023354"
      },
      "source": [
        "y = x + x\n",
        "print(y)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2  4  6  8 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7eGtY_Un3JC",
        "colab_type": "text"
      },
      "source": [
        "# **Part 2: Introduction to Autograd**\n",
        "\n",
        "## **역전파 자동화 하기**\n",
        "> 일단 신경망 출력에서 기울기를 계산한 뒤, 이 계산 결과를 끝에서 두 번째 구성요소의 미분계수 계산에 이용합니다. 그리고 아키텍처 내부의 모든 가중치가 정확한 기울기를 갖게 될 때까지 이 과정을 반복합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTIv405eo1SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Tensor (object):\n",
        "    \n",
        "    def __init__(self, data, creators=None, creation_op = None):\n",
        "        self.data = np.array(data)\n",
        "        self.creation_op = creation_op\n",
        "        self.creators = creators\n",
        "        self.grad = None\n",
        "    \n",
        "    def backward(self, grad):                ## 자동 미분\n",
        "        self.grad = grad\n",
        "        \n",
        "        if(self.creation_op == \"add\"):\n",
        "            self.creators[0].backward(grad)\n",
        "            self.creators[1].backward(grad)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return Tensor(self.data + other.data,  creators=[self,other], creation_op=\"add\")\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())\n",
        "\n",
        "x = Tensor([1,2,3,4,5])\n",
        "y = Tensor([2,2,2,2,2])\n",
        "\n",
        "z = x + y\n",
        "z.backward(Tensor(np.array([1,1,1,1,1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr7HGp3tpC9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "df7553c4-4019-4c04-b1d4-828b8192965d"
      },
      "source": [
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.creators)\n",
        "print(z.creation_op)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1]\n",
            "[1 1 1 1 1]\n",
            "[array([1, 2, 3, 4, 5]), array([2, 2, 2, 2, 2])]\n",
            "add\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YiMVpUkp7Rx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> ### autorad에서는 각 벡터가 자신의 모든 `self.creators`에 대해 `.backward()`를 호출하기 때문에 재귀적으로 동작함.\n",
        "\n",
        "\n",
        "\n",
        "### * 재귀적 : 자기 자신을 다시 이용하여 정의하거나 응용하는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WV_-DygpLXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c95a0893-095c-4c08-abaf-8c69d96267c6"
      },
      "source": [
        "a = Tensor([1,2,3,4,5])\n",
        "b = Tensor([2,2,2,2,2])\n",
        "c = Tensor([5,4,3,2,1])\n",
        "d = Tensor([-1,-2,-3,-4,-5])\n",
        "\n",
        "e = a + b\n",
        "f = c + d\n",
        "g = e + f\n",
        "g.backward(Tensor(np.array([1,1,1,1,1])))\n",
        "\n",
        "print(a.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ6UFaYirSNr",
        "colab_type": "text"
      },
      "source": [
        "## **Part 3: Tensors That Are Used Multiple Times** \n",
        "\n",
        "\n",
        "> Tensor의 현재 버전은 변수로의 역전파를 1회만 지원합니다.\n",
        "> 하지만 순전파를 하는 동안 텐서 (신경망의 가중치) 하나를 여러 번 재사용해야 하고 그래프의 각 부분은 경사도를 동일 텐서 안으로 역전파 합니다.\n",
        "> 그러나 코드는 현재 여러 번 사용된 변수로 역전파 하면 경사도를 정확히 계산할 수 없습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR3D5ytfqBrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bf4081b8-a9e4-4517-9eed-048800cc4e8f"
      },
      "source": [
        "a = Tensor([1,2,3,4,5])\n",
        "b = Tensor([2,2,2,2,2])\n",
        "c = Tensor([5,4,3,2,1])\n",
        "\n",
        "d = a + b\n",
        "e = b + c   # b 재사용됨\n",
        "f = d + e\n",
        "f.backward(Tensor(np.array([1,1,1,1,1])))\n",
        "\n",
        "b.grad.data == np.array([2,2,2,2,2])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vQiRx36rfcC",
        "colab_type": "text"
      },
      "source": [
        "## **Part 4: Upgrading Autograd to Support Multiple Tensors**\n",
        "\n",
        "\n",
        "###2가지 기능 추가!\n",
        "\n",
        "1.**경사도를 누적해서 변수가 한 번 이상 사용될 때 해당 변수가 모든 자식으로부터 경사도를 수신할 수 있도록 하는 기능**\n",
        "+) self.Children counter를 생성 --> 의도치 않게 같은 자식에서 두 번 이뤄지는 역전파로부터 변수 보호 가능\n",
        "\n",
        "2.**all_children_grads_accounted_for() 함수 추가.** 텐서가 graph 내의 모든 children으로부터 경사도를 수신했는지 계산하는 것.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUO-x1_6rcQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0d78e877-b220-4330-cccc-6a29100763d2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Tensor (object):\n",
        "    \n",
        "    def __init__(self,data,\n",
        "                 autograd=False,\n",
        "                 creators=None,\n",
        "                 creation_op=None,\n",
        "                 id=None):\n",
        "        \n",
        "        self.data = np.array(data)\n",
        "        self.autograd = autograd\n",
        "        self.grad = None\n",
        "        if(id is None):\n",
        "            self.id = np.random.randint(0,100000)\n",
        "        else:\n",
        "            self.id = id\n",
        "        \n",
        "        self.creators = creators\n",
        "        self.creation_op = creation_op\n",
        "        self.children = {}\n",
        "        \n",
        "        if(creators is not None):\n",
        "            for c in creators:\n",
        "                if(self.id not in c.children):          # tensor가 얼마나 많은 자식을 갖고 있는지 계속 추적\n",
        "                    c.children[self.id] = 1\n",
        "                else:\n",
        "                    c.children[self.id] += 1\n",
        "\n",
        "    def all_children_grads_accounted_for(self):         # tensor가 각 자식으로부터 수신한 경사도 개수가 정확한지 확인\n",
        "        for id,cnt in self.children.items():\n",
        "            if(cnt != 0):\n",
        "                return False\n",
        "        return True        \n",
        "        \n",
        "    def backward(self,grad=None, grad_origin=None):\n",
        "        if(self.autograd):\n",
        "            if(grad is None):\n",
        "                grad = FloatTensor(np.ones_like(self.data))\n",
        "            \n",
        "            if(grad_origin is not None):\n",
        "                if(self.children[grad_origin.id] == 0):     # 역전파가 가능한지 또는 경사도를 기다리고 있는 상태인지를 확인해서\n",
        "                    raise Exception(\"cannot backprop more than once\") # ㅎ경사도를 기다리고 있는 상태라면 카운터를 감소시킴\n",
        "                else:\n",
        "                    self.children[grad_origin.id] -= 1\n",
        "\n",
        "            if(self.grad is None):\n",
        "                self.grad = grad                            # 여러 자식의 경사도를 누적함.\n",
        "            else:\n",
        "                self.grad += grad\n",
        "            \n",
        "            # grads must not have grads of their own\n",
        "            assert grad.autograd == False\n",
        "            \n",
        "            # only continue backpropping if there's something to\n",
        "            # backprop into and if all gradients (from children)\n",
        "            # are accounted for override waiting for children if\n",
        "            # \"backprop\" was called on this variable directly\n",
        "            if(self.creators is not None and \n",
        "               (self.all_children_grads_accounted_for() or \n",
        "                grad_origin is None)):\n",
        "\n",
        "                if(self.creation_op == \"add\"):\n",
        "                    self.creators[0].backward(self.grad, self)\n",
        "                    self.creators[1].backward(self.grad, self)        # 실제 역전파를 시작\n",
        "                    \n",
        "    def __add__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data + other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"add\")\n",
        "        return Tensor(self.data + other.data)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())  \n",
        "    \n",
        "a = Tensor([1,2,3,4,5], autograd=True)\n",
        "b = Tensor([2,2,2,2,2], autograd=True)\n",
        "c = Tensor([5,4,3,2,1], autograd=True)\n",
        "\n",
        "d = a + b\n",
        "e = b + c\n",
        "f = d + e\n",
        "\n",
        "f.backward(Tensor(np.array([1,1,1,1,1])))\n",
        "\n",
        "print(b.grad.data == np.array([2,2,2,2,2]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTG6cTMFrlOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}