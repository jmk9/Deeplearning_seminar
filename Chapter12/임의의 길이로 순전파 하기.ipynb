{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', 'moved', 'to', 'the', 'bathroom.'], ['john', 'went', 'to', 'the', 'hallway.'], ['where', 'is', 'mary?', '\\tbathroom\\t1']]\n"
     ]
    }
   ],
   "source": [
    "import sys,random,math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "f = open('tasksv11/en/qa1_single-supporting-fact_train.txt','r')\n",
    "raw = f.readlines()\n",
    "f.close()\n",
    "\n",
    "tokens = list()\n",
    "for line in raw[0:1000]:\n",
    "    tokens.append(line.lower().replace(\"\\n\",\"\").split(\" \")[1:])\n",
    "\n",
    "print(tokens[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        vocab.add(word)\n",
    "\n",
    "vocab = list(vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word]=i\n",
    "    \n",
    "def words2indices(sentence):\n",
    "    idx = list()\n",
    "    for word in sentence:\n",
    "        idx.append(word2index[word])\n",
    "    return idx\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "embed_size = 10\n",
    "\n",
    "# word embeddings\n",
    "embed = (np.random.rand(len(vocab),embed_size) - 0.5) * 0.1\n",
    "\n",
    "# embedding -> embedding (initially the identity matrix)\n",
    "recurrent = np.eye(embed_size)\n",
    "\n",
    "# sentence embedding for empty sentence\n",
    "start = np.zeros(embed_size)\n",
    "\n",
    "# embedding -> output weights\n",
    "decoder = (np.random.rand(embed_size, len(vocab)) - 0.5) * 0.1\n",
    "\n",
    "# one hot lookups (for loss function)\n",
    "one_hot = np.eye(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임의의 길이로 순전파 하기\n",
    "다음 코드는 순전파와 더불어 다음 단어 예측에 대한 논리를 담고 있습니다. 낮설게 느껴지는 구성에도 불구하고, 단위행렬을 이용하는 ㄴ동안 임베딩을 총합하기 위해 따르는 절차는 에전과 동일합니다.  \n",
    ".  \n",
    "앞서 말한 바와 같이 이겨에서 단위행렬은 모두 0으로 초기화 되는  recurrent라 불리는 행렬로 대체됩니다. 이 행렬은 학습을 통해 새로운 값을 얻습니다.  \n",
    ".  \n",
    "또한 마지막 단어만 예측하는게 아니라 이전 단어까지 생성된 임베딩에 기초해서 다음 단어를 계속 예측해 나갑니다. 이렇게 하면 매번 순전파를 다시 하는 것 보다 효율이 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    \n",
    "    layers = list()\n",
    "    layer = {}\n",
    "    layer['hidden'] = start\n",
    "    layers.append(layer)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # forward propagate\n",
    "    preds = list()\n",
    "    for target_i in range(len(sent)):\n",
    "\n",
    "        layer = {}\n",
    "\n",
    "        # try to predict the next term\n",
    "        layer['pred'] = softmax(layers[-1]['hidden'].dot(decoder))\n",
    "\n",
    "        loss += -np.log(layer['pred'][sent[target_i]])\n",
    "\n",
    "        # generate the next hidden state\n",
    "        layer['hidden'] = layers[-1]['hidden'].dot(recurrent) + embed[sent[target_i]]\n",
    "        layers.append(layer)\n",
    "\n",
    "    return layers, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *layers = list()\n",
    "layers 리스트는 순전파를 위한 새로운 방법입니다. 우리가 사용하는 문장(sent)의 길이가 커지면 더 많은 순전파를 해야합니다. 결과적으로 예전처럼 정적 게층 변수를 사용할 수 없습니다. 이제 레이어가 얼마나 필요한지에 따라 이 목록에 새 계층을 붙여나가야 합니다.\n",
    "\n",
    "## 임의의 길이로 역전파 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward\n",
    "for iter in range(30000):\n",
    "    alpha = 0.001\n",
    "    sent = words2indices(tokens[iter%len(tokens)][1:])\n",
    "    layers,loss = predict(sent) \n",
    "\n",
    "    # back propagate\n",
    "    for layer_idx in reversed(range(len(layers))):\n",
    "        layer = layers[layer_idx]\n",
    "        target = sent[layer_idx-1]\n",
    "\n",
    "        if(layer_idx > 0):  # if not the first layer\n",
    "            layer['output_delta'] = layer['pred'] - one_hot[target]\n",
    "            new_hidden_delta = layer['output_delta'].dot(decoder.transpose())\n",
    "\n",
    "            # if the last layer - don't pull from a later one becasue it doesn't exist\n",
    "            if(layer_idx == len(layers)-1):\n",
    "                layer['hidden_delta'] = new_hidden_delta\n",
    "            else:\n",
    "                layer['hidden_delta'] = new_hidden_delta + layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
    "        else: # if the first layer\n",
    "            layer['hidden_delta'] = layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 가중 중요한 객체는 두 백터 __layer['state']__ 와 __layer['previous->hidden']__ 을 가지는 리스트 입니다.  \n",
    ".  \n",
    "p.296\n",
    "역전파를 위해 출력 경사도를 취하고 layer['state_delta'] 리스트에 새 객체를 ~... (이해 안됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_delta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-16f452e4a595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_delta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'state_delta'"
     ]
    }
   ],
   "source": [
    "print(layer['state_delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임의의 길이로 가중치 갱신하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:82.0566976843772\n",
      "Perplexity:81.94764300940292\n",
      "Perplexity:81.81416657357991\n",
      "Perplexity:81.59412969960367\n",
      "Perplexity:81.17331705643828\n",
      "Perplexity:80.29954869033996\n",
      "Perplexity:78.29959197561286\n",
      "Perplexity:72.674561086639\n",
      "Perplexity:47.88995969948321\n",
      "Perplexity:26.52416250957102\n",
      "Perplexity:20.380986739036135\n",
      "Perplexity:18.978758195087\n",
      "Perplexity:17.775942823242435\n",
      "Perplexity:16.167361954388213\n",
      "Perplexity:13.734666073001964\n",
      "Perplexity:10.513795471360048\n",
      "Perplexity:7.9915610417086445\n",
      "Perplexity:6.674904932962154\n",
      "Perplexity:5.833786860862074\n",
      "Perplexity:5.31184481263934\n",
      "Perplexity:4.986882111200132\n",
      "Perplexity:4.769468999586203\n",
      "Perplexity:4.633500775989438\n",
      "Perplexity:4.555171751365457\n",
      "Perplexity:4.498465005274975\n",
      "Perplexity:4.436391759941303\n",
      "Perplexity:4.36170951635081\n",
      "Perplexity:4.278600777153254\n",
      "Perplexity:4.195052826175365\n",
      "Perplexity:4.118177548939387\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "for iter in range(30000):\n",
    "    alpha = 0.001\n",
    "    sent = words2indices(tokens[iter%len(tokens)][1:])\n",
    "\n",
    "    layers,loss = predict(sent) \n",
    "\n",
    "    # back propagate\n",
    "    for layer_idx in reversed(range(len(layers))):\n",
    "        layer = layers[layer_idx]\n",
    "        target = sent[layer_idx-1]\n",
    "\n",
    "        if(layer_idx > 0):\n",
    "            layer['output_delta'] = layer['pred'] - one_hot[target]\n",
    "            new_hidden_delta = layer['output_delta'].dot(decoder.transpose())\n",
    "\n",
    "            # if the last layer - don't pull from a \n",
    "            # later one becasue it doesn't exist\n",
    "            if(layer_idx == len(layers)-1):\n",
    "                layer['hidden_delta'] = new_hidden_delta\n",
    "            else:\n",
    "                layer['hidden_delta'] = new_hidden_delta + layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
    "        else:\n",
    "            layer['hidden_delta'] = layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
    "\n",
    "    # update weights\n",
    "    start -= layers[0]['hidden_delta'] * alpha / float(len(sent))\n",
    "    for layer_idx,layer in enumerate(layers[1:]):\n",
    "        \n",
    "        decoder -= np.outer(layers[layer_idx]['hidden'], layer['output_delta']) * alpha / float(len(sent))\n",
    "        \n",
    "        embed_idx = sent[layer_idx]\n",
    "        embed[embed_idx] -= layers[layer_idx]['hidden_delta'] * alpha / float(len(sent))\n",
    "        recurrent -= np.outer(layers[layer_idx]['hidden'], layer['hidden_delta']) * alpha / float(len(sent))\n",
    "        \n",
    "    if(iter % 1000 == 0):\n",
    "        print(\"Perplexity:\" + str(np.exp(loss/len(sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred': array([3.09322309e-03, 5.90908061e-02, 3.41626197e-03, 4.47881817e-03,\n",
      "       9.51865060e-03, 1.04168006e-02, 6.51265513e-03, 7.22911944e-03,\n",
      "       1.66065489e-05, 1.19658474e-03, 1.52570415e-02, 7.18232246e-03,\n",
      "       1.45451566e-07, 1.25677359e-03, 3.75678169e-03, 7.40964444e-17,\n",
      "       1.05738710e-07, 1.43145683e-35, 1.51321723e-07, 6.82884940e-03,\n",
      "       2.20939866e-04, 4.80428078e-03, 3.35710562e-03, 4.13364433e-03,\n",
      "       5.84293785e-03, 8.33966142e-03, 1.91781120e-03, 2.92680579e-20,\n",
      "       4.34974409e-03, 2.07949560e-03, 4.93524290e-03, 1.08092130e-07,\n",
      "       1.65655112e-16, 2.31616118e-03, 7.13579325e-17, 3.12836075e-01,\n",
      "       7.46446061e-03, 3.21406548e-05, 4.95075323e-03, 2.44549903e-03,\n",
      "       3.84033610e-24, 4.79626081e-03, 8.67148445e-03, 1.05599677e-02,\n",
      "       9.05985179e-06, 4.23988231e-02, 5.80906812e-03, 2.56995885e-03,\n",
      "       4.32574283e-03, 1.62065514e-04, 1.44515929e-01, 3.15492164e-03,\n",
      "       1.34510975e-03, 5.80566417e-04, 3.51810617e-03, 1.52639192e-02,\n",
      "       8.73100052e-03, 1.51814861e-03, 4.02718770e-02, 9.75278802e-04,\n",
      "       1.59986696e-02, 1.06087593e-02, 3.57223241e-03, 9.04740982e-02,\n",
      "       2.59739983e-03, 3.48701284e-03, 9.99136512e-03, 4.44721971e-03,\n",
      "       8.86810314e-03, 1.34504419e-02, 7.04179682e-03, 7.18800042e-04,\n",
      "       1.89777512e-03, 5.20817237e-03, 3.16274504e-03, 1.06198279e-03,\n",
      "       5.42382687e-15, 9.65825531e-04, 5.16482991e-03, 1.01627751e-05,\n",
      "       2.81372614e-03, 3.83357928e-06]), 'hidden': array([ 22.08339962,  40.96657036,  19.57358945, -62.99025373,\n",
      "       -47.41021967, -45.43701924,  87.19829197,  28.34377482,\n",
      "       176.06451737,   8.11521233]), 'output_delta': array([ 3.09322309e-03, -9.40909194e-01,  3.41626197e-03,  4.47881817e-03,\n",
      "        9.51865060e-03,  1.04168006e-02,  6.51265513e-03,  7.22911944e-03,\n",
      "        1.66065489e-05,  1.19658474e-03,  1.52570415e-02,  7.18232246e-03,\n",
      "        1.45451566e-07,  1.25677359e-03,  3.75678169e-03,  7.40964444e-17,\n",
      "        1.05738710e-07,  1.43145683e-35,  1.51321723e-07,  6.82884940e-03,\n",
      "        2.20939866e-04,  4.80428078e-03,  3.35710562e-03,  4.13364433e-03,\n",
      "        5.84293785e-03,  8.33966142e-03,  1.91781120e-03,  2.92680579e-20,\n",
      "        4.34974409e-03,  2.07949560e-03,  4.93524290e-03,  1.08092130e-07,\n",
      "        1.65655112e-16,  2.31616118e-03,  7.13579325e-17,  3.12836075e-01,\n",
      "        7.46446061e-03,  3.21406548e-05,  4.95075323e-03,  2.44549903e-03,\n",
      "        3.84033610e-24,  4.79626081e-03,  8.67148445e-03,  1.05599677e-02,\n",
      "        9.05985179e-06,  4.23988231e-02,  5.80906812e-03,  2.56995885e-03,\n",
      "        4.32574283e-03,  1.62065514e-04,  1.44515929e-01,  3.15492164e-03,\n",
      "        1.34510975e-03,  5.80566417e-04,  3.51810617e-03,  1.52639192e-02,\n",
      "        8.73100052e-03,  1.51814861e-03,  4.02718770e-02,  9.75278802e-04,\n",
      "        1.59986696e-02,  1.06087593e-02,  3.57223241e-03,  9.04740982e-02,\n",
      "        2.59739983e-03,  3.48701284e-03,  9.99136512e-03,  4.44721971e-03,\n",
      "        8.86810314e-03,  1.34504419e-02,  7.04179682e-03,  7.18800042e-04,\n",
      "        1.89777512e-03,  5.20817237e-03,  3.16274504e-03,  1.06198279e-03,\n",
      "        5.42382687e-15,  9.65825531e-04,  5.16482991e-03,  1.01627751e-05,\n",
      "        2.81372614e-03,  3.83357928e-06]), 'hidden_delta': array([ 0.01513293, -0.01501648,  0.02311971, -0.03414636,  0.05184683,\n",
      "        0.02182559, -0.03733255,  0.02618272, -0.00625343, -0.0215472 ])}\n"
     ]
    }
   ],
   "source": [
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hidden': array([-0.14440977, -0.64322309, -0.38912413,  0.92394088,  0.73134444,\n",
      "        0.44317634, -1.29727156, -0.06075412, -2.22825832, -0.19572764]), 'hidden_delta': array([-1.8179834 ,  2.84122844,  3.3245737 , -4.73683072, -1.06793371,\n",
      "        1.735225  ,  1.64472729, -0.24782412,  2.43019301,  1.74300169])}, {'pred': array([0.00250279, 0.00180992, 0.00261685, 0.00265425, 0.00283986,\n",
      "       0.00296343, 0.00262232, 0.00266671, 0.00248541, 0.00252136,\n",
      "       0.00270822, 0.00279038, 0.02761   , 0.00265442, 0.00266756,\n",
      "       0.04700664, 0.0276076 , 0.23882146, 0.026897  , 0.00291577,\n",
      "       0.00248728, 0.0025921 , 0.00254163, 0.0025273 , 0.00277493,\n",
      "       0.00282061, 0.00249426, 0.15087278, 0.00282713, 0.00245812,\n",
      "       0.00269479, 0.02866904, 0.04370904, 0.00258643, 0.04622024,\n",
      "       0.00158624, 0.00265165, 0.00259994, 0.00265406, 0.00258483,\n",
      "       0.09710975, 0.00289152, 0.00306267, 0.00305908, 0.00263474,\n",
      "       0.00182275, 0.00260153, 0.00245802, 0.00269992, 0.00244972,\n",
      "       0.00174606, 0.00308441, 0.00254088, 0.00250586, 0.00265178,\n",
      "       0.00288755, 0.00254616, 0.00238775, 0.00171153, 0.00268618,\n",
      "       0.00304343, 0.00311626, 0.00280887, 0.00166702, 0.00273477,\n",
      "       0.00250623, 0.00268424, 0.00277917, 0.00294609, 0.00278285,\n",
      "       0.00285244, 0.00243969, 0.02315631, 0.00257563, 0.00253042,\n",
      "       0.0024564 , 0.06069876, 0.00243416, 0.00246623, 0.00277832,\n",
      "       0.00256335, 0.00272709]), 'hidden': array([-1.65671717,  0.13306333, -0.02524301,  0.48699057,  1.29359101,\n",
      "        3.75070215, -5.08527175,  0.18021398, -6.89679778,  0.28958729]), 'output_delta': array([ 0.00250279,  0.00180992,  0.00261685,  0.00265425,  0.00283986,\n",
      "        0.00296343,  0.00262232,  0.00266671,  0.00248541,  0.00252136,\n",
      "        0.00270822,  0.00279038,  0.02761   ,  0.00265442,  0.00266756,\n",
      "        0.04700664,  0.0276076 ,  0.23882146,  0.026897  ,  0.00291577,\n",
      "        0.00248728,  0.0025921 ,  0.00254163,  0.0025273 ,  0.00277493,\n",
      "        0.00282061,  0.00249426,  0.15087278,  0.00282713,  0.00245812,\n",
      "        0.00269479,  0.02866904,  0.04370904,  0.00258643,  0.04622024,\n",
      "        0.00158624,  0.00265165,  0.00259994,  0.00265406,  0.00258483,\n",
      "       -0.90289025,  0.00289152,  0.00306267,  0.00305908,  0.00263474,\n",
      "        0.00182275,  0.00260153,  0.00245802,  0.00269992,  0.00244972,\n",
      "        0.00174606,  0.00308441,  0.00254088,  0.00250586,  0.00265178,\n",
      "        0.00288755,  0.00254616,  0.00238775,  0.00171153,  0.00268618,\n",
      "        0.00304343,  0.00311626,  0.00280887,  0.00166702,  0.00273477,\n",
      "        0.00250623,  0.00268424,  0.00277917,  0.00294609,  0.00278285,\n",
      "        0.00285244,  0.00243969,  0.02315631,  0.00257563,  0.00253042,\n",
      "        0.0024564 ,  0.06069876,  0.00243416,  0.00246623,  0.00277832,\n",
      "        0.00256335,  0.00272709]), 'hidden_delta': array([ 0.41412451,  0.34837458,  0.2679536 , -0.84698513,  0.66673766,\n",
      "       -0.71032595, -0.32160355,  1.8231224 ,  1.54282207, -0.16250357])}, {'pred': array([5.04910259e-06, 1.78597563e-06, 6.24068224e-06, 6.56459155e-06,\n",
      "       9.44910321e-06, 1.06009331e-05, 6.58188425e-06, 6.82285065e-06,\n",
      "       2.98591343e-06, 4.66776238e-06, 7.92399696e-06, 8.66284285e-06,\n",
      "       1.58251494e-02, 5.87980328e-06, 6.45300184e-06, 1.43085393e-02,\n",
      "       1.49486252e-02, 9.21986815e-02, 1.43696093e-02, 9.83018597e-06,\n",
      "       3.86423276e-06, 6.25297065e-06, 5.53321628e-06, 5.50727650e-06,\n",
      "       7.77601914e-06, 8.55292241e-06, 4.80028225e-06, 6.81819859e-01,\n",
      "       8.05882777e-06, 4.55605622e-06, 6.87051803e-06, 1.75524406e-02,\n",
      "       1.16575237e-02, 5.58947104e-06, 1.30662957e-02, 1.28222564e-06,\n",
      "       6.96422797e-06, 3.84030695e-06, 6.73794771e-06, 5.70074798e-06,\n",
      "       4.09601754e-02, 9.30839601e-06, 1.17963321e-05, 1.18730536e-05,\n",
      "       3.49813494e-06, 1.80854835e-06, 6.06226085e-06, 4.71782319e-06,\n",
      "       6.98752449e-06, 3.54365217e-06, 1.75539010e-06, 1.12831248e-05,\n",
      "       4.92039945e-06, 4.28232125e-06, 6.49832264e-06, 1.00684497e-05,\n",
      "       5.79425652e-06, 3.88112435e-06, 1.37545665e-06, 6.12313748e-06,\n",
      "       1.28143200e-05, 1.35397042e-05, 8.11773949e-06, 1.32512276e-06,\n",
      "       7.12950778e-06, 5.08113715e-06, 7.46725678e-06, 8.00080277e-06,\n",
      "       1.05584206e-05, 8.78309325e-06, 8.97870162e-06, 3.96541920e-06,\n",
      "       2.00284957e-02, 5.96916005e-06, 5.34401057e-06, 4.31428892e-06,\n",
      "       6.28236940e-02, 4.09777609e-06, 4.91838285e-06, 4.35468001e-06,\n",
      "       5.51064604e-06, 3.67691103e-06]), 'hidden': array([ -6.62823614,   4.73227269,   2.53675127,  -3.94829326,\n",
      "        -1.4516809 ,  13.32500135, -10.36357364,  -2.1158558 ,\n",
      "       -13.80527619,   2.92107322]), 'output_delta': array([ 5.04910259e-06,  1.78597563e-06,  6.24068224e-06,  6.56459155e-06,\n",
      "        9.44910321e-06,  1.06009331e-05,  6.58188425e-06,  6.82285065e-06,\n",
      "        2.98591343e-06,  4.66776238e-06,  7.92399696e-06,  8.66284285e-06,\n",
      "        1.58251494e-02,  5.87980328e-06,  6.45300184e-06,  1.43085393e-02,\n",
      "        1.49486252e-02,  9.21986815e-02,  1.43696093e-02,  9.83018597e-06,\n",
      "        3.86423276e-06,  6.25297065e-06,  5.53321628e-06,  5.50727650e-06,\n",
      "        7.77601914e-06,  8.55292241e-06,  4.80028225e-06, -3.18180141e-01,\n",
      "        8.05882777e-06,  4.55605622e-06,  6.87051803e-06,  1.75524406e-02,\n",
      "        1.16575237e-02,  5.58947104e-06,  1.30662957e-02,  1.28222564e-06,\n",
      "        6.96422797e-06,  3.84030695e-06,  6.73794771e-06,  5.70074798e-06,\n",
      "        4.09601754e-02,  9.30839601e-06,  1.17963321e-05,  1.18730536e-05,\n",
      "        3.49813494e-06,  1.80854835e-06,  6.06226085e-06,  4.71782319e-06,\n",
      "        6.98752449e-06,  3.54365217e-06,  1.75539010e-06,  1.12831248e-05,\n",
      "        4.92039945e-06,  4.28232125e-06,  6.49832264e-06,  1.00684497e-05,\n",
      "        5.79425652e-06,  3.88112435e-06,  1.37545665e-06,  6.12313748e-06,\n",
      "        1.28143200e-05,  1.35397042e-05,  8.11773949e-06,  1.32512276e-06,\n",
      "        7.12950778e-06,  5.08113715e-06,  7.46725678e-06,  8.00080277e-06,\n",
      "        1.05584206e-05,  8.78309325e-06,  8.97870162e-06,  3.96541920e-06,\n",
      "        2.00284957e-02,  5.96916005e-06,  5.34401057e-06,  4.31428892e-06,\n",
      "        6.28236940e-02,  4.09777609e-06,  4.91838285e-06,  4.35468001e-06,\n",
      "        5.51064604e-06,  3.67691103e-06]), 'hidden_delta': array([ 0.3142373 , -0.22757129, -0.13321191,  0.13323413,  0.49598815,\n",
      "       -0.44884589, -0.2727966 ,  0.69093374,  0.20792934, -0.2162394 ])}, {'pred': array([7.27738363e-10, 2.21389377e-10, 1.06156417e-09, 1.48663780e-09,\n",
      "       3.62130224e-09, 6.40697660e-09, 1.52428471e-09, 2.11826010e-09,\n",
      "       5.63623745e-11, 5.28764136e-10, 3.41570851e-09, 2.66995474e-09,\n",
      "       3.73992565e-02, 7.86258066e-10, 1.58356058e-09, 2.22219626e-04,\n",
      "       3.46506505e-02, 1.25064883e-06, 2.89073002e-02, 4.22704763e-09,\n",
      "       1.88403953e-10, 1.09622661e-09, 7.87392792e-10, 8.70954055e-10,\n",
      "       2.95579326e-09, 3.96025667e-09, 5.64927026e-10, 1.20874498e-01,\n",
      "       2.90546361e-09, 5.16477506e-10, 1.89156399e-09, 4.71542929e-02,\n",
      "       1.67746474e-04, 8.88623542e-10, 1.87372156e-04, 1.45460277e-10,\n",
      "       1.86042859e-09, 1.09982764e-10, 1.45912330e-09, 8.13421937e-10,\n",
      "       7.33413574e-05, 3.30736901e-09, 8.43997423e-09, 9.63282373e-09,\n",
      "       7.34622172e-11, 1.81972182e-10, 1.57458171e-09, 5.34590093e-10,\n",
      "       1.66199873e-09, 1.42535940e-10, 2.11219304e-10, 4.82807311e-09,\n",
      "       5.63813189e-10, 3.35128476e-10, 1.29253883e-09, 6.06735926e-09,\n",
      "       1.56641302e-09, 3.69262833e-10, 1.19091695e-10, 7.71238371e-10,\n",
      "       8.91707156e-09, 9.20016206e-09, 2.05027670e-09, 1.34905879e-10,\n",
      "       1.39278884e-09, 8.27528390e-10, 2.41206963e-09, 2.05713874e-09,\n",
      "       5.21833738e-09, 4.03450486e-09, 3.79323671e-09, 3.05170646e-10,\n",
      "       7.17700815e-01, 1.22490153e-09, 7.95789929e-10, 3.63434250e-10,\n",
      "       1.26611179e-02, 3.23470885e-10, 8.86054754e-10, 1.21722073e-10,\n",
      "       8.77642640e-10, 6.64303277e-11]), 'hidden': array([-11.49719757,  23.29186475,  13.7247988 , -28.52654549,\n",
      "       -16.70253843,  20.20280871,   1.26301851,   0.26022906,\n",
      "        14.85292286,  10.3810792 ]), 'output_delta': array([ 7.27738363e-10,  2.21389377e-10,  1.06156417e-09,  1.48663780e-09,\n",
      "        3.62130224e-09,  6.40697660e-09,  1.52428471e-09,  2.11826010e-09,\n",
      "        5.63623745e-11,  5.28764136e-10,  3.41570851e-09,  2.66995474e-09,\n",
      "        3.73992565e-02,  7.86258066e-10,  1.58356058e-09,  2.22219626e-04,\n",
      "        3.46506505e-02,  1.25064883e-06,  2.89073002e-02,  4.22704763e-09,\n",
      "        1.88403953e-10,  1.09622661e-09,  7.87392792e-10,  8.70954055e-10,\n",
      "        2.95579326e-09,  3.96025667e-09,  5.64927026e-10,  1.20874498e-01,\n",
      "        2.90546361e-09,  5.16477506e-10,  1.89156399e-09,  4.71542929e-02,\n",
      "        1.67746474e-04,  8.88623542e-10,  1.87372156e-04,  1.45460277e-10,\n",
      "        1.86042859e-09,  1.09982764e-10,  1.45912330e-09,  8.13421937e-10,\n",
      "        7.33413574e-05,  3.30736901e-09,  8.43997423e-09,  9.63282373e-09,\n",
      "        7.34622172e-11,  1.81972182e-10,  1.57458171e-09,  5.34590093e-10,\n",
      "        1.66199873e-09,  1.42535940e-10,  2.11219304e-10,  4.82807311e-09,\n",
      "        5.63813189e-10,  3.35128476e-10,  1.29253883e-09,  6.06735926e-09,\n",
      "        1.56641302e-09,  3.69262833e-10,  1.19091695e-10,  7.71238371e-10,\n",
      "        8.91707156e-09,  9.20016206e-09,  2.05027670e-09,  1.34905879e-10,\n",
      "        1.39278884e-09,  8.27528390e-10,  2.41206963e-09,  2.05713874e-09,\n",
      "        5.21833738e-09,  4.03450486e-09,  3.79323671e-09,  3.05170646e-10,\n",
      "       -2.82299185e-01,  1.22490153e-09,  7.95789929e-10,  3.63434250e-10,\n",
      "        1.26611179e-02,  3.23470885e-10,  8.86054754e-10,  1.21722073e-10,\n",
      "        8.77642640e-10,  6.64303277e-11]), 'hidden_delta': array([ 0.05886154, -0.08567904, -0.01762598,  0.04272226,  0.20932466,\n",
      "       -0.08353309, -0.13108328,  0.16384166, -0.07082599, -0.08502409])}, {'pred': array([3.09322309e-03, 5.90908061e-02, 3.41626197e-03, 4.47881817e-03,\n",
      "       9.51865060e-03, 1.04168006e-02, 6.51265513e-03, 7.22911944e-03,\n",
      "       1.66065489e-05, 1.19658474e-03, 1.52570415e-02, 7.18232246e-03,\n",
      "       1.45451566e-07, 1.25677359e-03, 3.75678169e-03, 7.40964444e-17,\n",
      "       1.05738710e-07, 1.43145683e-35, 1.51321723e-07, 6.82884940e-03,\n",
      "       2.20939866e-04, 4.80428078e-03, 3.35710562e-03, 4.13364433e-03,\n",
      "       5.84293785e-03, 8.33966142e-03, 1.91781120e-03, 2.92680579e-20,\n",
      "       4.34974409e-03, 2.07949560e-03, 4.93524290e-03, 1.08092130e-07,\n",
      "       1.65655112e-16, 2.31616118e-03, 7.13579325e-17, 3.12836075e-01,\n",
      "       7.46446061e-03, 3.21406548e-05, 4.95075323e-03, 2.44549903e-03,\n",
      "       3.84033610e-24, 4.79626081e-03, 8.67148445e-03, 1.05599677e-02,\n",
      "       9.05985179e-06, 4.23988231e-02, 5.80906812e-03, 2.56995885e-03,\n",
      "       4.32574283e-03, 1.62065514e-04, 1.44515929e-01, 3.15492164e-03,\n",
      "       1.34510975e-03, 5.80566417e-04, 3.51810617e-03, 1.52639192e-02,\n",
      "       8.73100052e-03, 1.51814861e-03, 4.02718770e-02, 9.75278802e-04,\n",
      "       1.59986696e-02, 1.06087593e-02, 3.57223241e-03, 9.04740982e-02,\n",
      "       2.59739983e-03, 3.48701284e-03, 9.99136512e-03, 4.44721971e-03,\n",
      "       8.86810314e-03, 1.34504419e-02, 7.04179682e-03, 7.18800042e-04,\n",
      "       1.89777512e-03, 5.20817237e-03, 3.16274504e-03, 1.06198279e-03,\n",
      "       5.42382687e-15, 9.65825531e-04, 5.16482991e-03, 1.01627751e-05,\n",
      "       2.81372614e-03, 3.83357928e-06]), 'hidden': array([ 22.08339962,  40.96657036,  19.57358945, -62.99025373,\n",
      "       -47.41021967, -45.43701924,  87.19829197,  28.34377482,\n",
      "       176.06451737,   8.11521233]), 'output_delta': array([ 3.09322309e-03, -9.40909194e-01,  3.41626197e-03,  4.47881817e-03,\n",
      "        9.51865060e-03,  1.04168006e-02,  6.51265513e-03,  7.22911944e-03,\n",
      "        1.66065489e-05,  1.19658474e-03,  1.52570415e-02,  7.18232246e-03,\n",
      "        1.45451566e-07,  1.25677359e-03,  3.75678169e-03,  7.40964444e-17,\n",
      "        1.05738710e-07,  1.43145683e-35,  1.51321723e-07,  6.82884940e-03,\n",
      "        2.20939866e-04,  4.80428078e-03,  3.35710562e-03,  4.13364433e-03,\n",
      "        5.84293785e-03,  8.33966142e-03,  1.91781120e-03,  2.92680579e-20,\n",
      "        4.34974409e-03,  2.07949560e-03,  4.93524290e-03,  1.08092130e-07,\n",
      "        1.65655112e-16,  2.31616118e-03,  7.13579325e-17,  3.12836075e-01,\n",
      "        7.46446061e-03,  3.21406548e-05,  4.95075323e-03,  2.44549903e-03,\n",
      "        3.84033610e-24,  4.79626081e-03,  8.67148445e-03,  1.05599677e-02,\n",
      "        9.05985179e-06,  4.23988231e-02,  5.80906812e-03,  2.56995885e-03,\n",
      "        4.32574283e-03,  1.62065514e-04,  1.44515929e-01,  3.15492164e-03,\n",
      "        1.34510975e-03,  5.80566417e-04,  3.51810617e-03,  1.52639192e-02,\n",
      "        8.73100052e-03,  1.51814861e-03,  4.02718770e-02,  9.75278802e-04,\n",
      "        1.59986696e-02,  1.06087593e-02,  3.57223241e-03,  9.04740982e-02,\n",
      "        2.59739983e-03,  3.48701284e-03,  9.99136512e-03,  4.44721971e-03,\n",
      "        8.86810314e-03,  1.34504419e-02,  7.04179682e-03,  7.18800042e-04,\n",
      "        1.89777512e-03,  5.20817237e-03,  3.16274504e-03,  1.06198279e-03,\n",
      "        5.42382687e-15,  9.65825531e-04,  5.16482991e-03,  1.01627751e-05,\n",
      "        2.81372614e-03,  3.83357928e-06]), 'hidden_delta': array([ 0.01513293, -0.01501648,  0.02311971, -0.03414636,  0.05184683,\n",
      "        0.02182559, -0.03733255,  0.02618272, -0.00625343, -0.0215472 ])}]\n"
     ]
    }
   ],
   "source": [
    "print(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행과 출력 분석\n",
    "이 코드를 실행하면 perplexity(혼란도)가 꾸준한 하락세를 보입니다. 이 혼란도는 로그함수를 거쳐 전달된 negated exponented label의 확률입니다(??)  \n",
    ".  \n",
    "하지만 혼란도가 이론적으로 나타내는 바는 두 함수의 분포의 차이입니다. 우리 에제에서 완벽한 확룰 분포는 정확한 단어에 대해서는 100% 나머지엔 0%가 될 것 입니다.  \n",
    ".  \n",
    "혼란도는 두 함수 분포가 일치하지 않을 때 높고, 일치할 때는 낮습니다(1에 근접). 그러므로 감소하는 혼란도는 좋은것입니다. 뿐만아니라 감소하는 혼란도는 데이터와 일치하는 에측확률을 학습하고 있다는 것을 의미합니다.\n",
    ".  \n",
    "그러나 혼란도는 가중치 안에서 무슨 일이 진행되고 있는지는 설명해주지 않습니다. 그래서 혼란도는 지표로써 과용되고 있다는 비판에 직면해 왔습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sandra', 'moved', 'to', 'the', 'garden.']\n",
      "Prev Input:sandra      True:moved          Pred:is\n",
      "Prev Input:moved       True:to             Pred:to\n",
      "Prev Input:to          True:the            Pred:the\n",
      "Prev Input:the         True:garden.        Pred:bedroom.\n"
     ]
    }
   ],
   "source": [
    "sent_index = 4\n",
    "\n",
    "l,_ = predict(words2indices(tokens[sent_index]))\n",
    "\n",
    "print(tokens[sent_index])\n",
    "\n",
    "for i,each_layer in enumerate(l[1:-1]):\n",
    "    input = tokens[sent_index][i]\n",
    "    true = tokens[sent_index][i+1]\n",
    "    pred = vocab[each_layer['pred'].argmax()]\n",
    "    print(\"Prev Input:\" + input + (' ' * (12 - len(input))) +\\\n",
    "          \"True:\" + true + (\" \" * (15 - len(true))) + \"Pred:\" + pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드는 문장을 취해서 해당 모델이 가장 가능성이 높다고 생각하는 단어를 예측합니다.  \n",
    "### 예측을 관찰하면 무슨 일이 벌어지는지 이해할 수 있습니다\n",
    "신경망이 학습하는 과정에서 출력된 예측 결과를 살펴보면 어떤 패턴을 고르는지 뿐만 아니라, 어떤 순서로 학습하는지도 알 수 있습니다. 아래 출력은 신경망이 학습을 100단계 진행한 후의 출력입니다.\n",
    "![title](https://github.com/limsonghwan/shwan/blob/master/100.jpg?raw=true)\n",
    "신경망은 무작위 적으로 시작합니다. 위 출력은 첫 무작위 상태에 편향되었을 가능성이 높습니다.  \n",
    "\n",
    "![title](https://github.com/limsonghwan/shwan/blob/master/10000.jpg?raw=true)\n",
    "위 출력은 학습을 10000회 후 출력입니다. 신경망은 가장 흔한 단어(the)를 고르고 매 시간마다 'the'로 예측합니다. 이것은 흔한 오류로 순환 신경망이 크게 왜곡된 데이터셋 안의 자세한 세부사항을 익히기 위해선 많은 학습을 거쳐야 합니다.  \n",
    "![title](https://github.com/limsonghwan/shwan/blob/master/final.jpg?raw=true)\n",
    "최종 출력입니다. 신경망은 모두 그럴듯한 예측을 해냈습니다. 그러나 신경망이 이 과업을 완벽하게 해결하도록 만드는 방법은 거의 없다는 사실을 알아두는 것이 매우 중요합니다. 사람도 'sandra moved to the'이후에 올 단어를 맞출 수 없습니다. 더 많은 맥락정보가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
